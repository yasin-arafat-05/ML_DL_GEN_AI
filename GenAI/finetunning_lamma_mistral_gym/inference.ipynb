{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rlk5v87j8tS3",
        "outputId": "32ffed4f-9d76-420b-bbb4-3710cd0aee1c"
      },
      "outputs": [],
      "source": [
        "%pip install transformers bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "SNppxa-C9-RS",
        "outputId": "05d0b016-1ef5-4b5d-9d48-bec377e16971"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52-cUV5X9E-H",
        "outputId": "db968423-5f82-4c2c-d795-7132c13a9f63"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/merged_model_final.zip  -d ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3TQ0_CY8PwB",
        "outputId": "bb200091-ba82-4965-8ca3-9b411c871cd3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True, \n",
        ")\n",
        "\n",
        "# Load the model with the quantization config\n",
        "merged_model_new = AutoModelForCausalLM.from_pretrained(\n",
        "    \"./saved_model\",\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config, \n",
        ")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./saved_model\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6rJkZAL9x8s",
        "outputId": "46f1bb73-57c4-42c1-e866-2ddef32a1677"
      },
      "outputs": [],
      "source": [
        "\n",
        "prompt = \"hey! i am begginer. and i want to do gym\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(merged_model_new.device)\n",
        "\n",
        "generated_ids = merged_model_new.generate(\n",
        "    inputs.input_ids,\n",
        "    max_length=1000,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
